{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5OEhIGUoxr0"
      },
      "source": [
        "# Predicting the Winning Football Team\n",
        "\n",
        "- Sports betting is a 500 billion dollar market (Sydney Herald)\n",
        "\n",
        "- Football is played by 250 million players in over 200 countries (most popular sport globally).\n",
        "- The English Premier League is the most popular domestic team in the world.\n",
        "- Design a predictive model capable of accurately predicting if the home team will win a football match?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvXEiFWuoxr4"
      },
      "source": [
        "**Discription of Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68FMMQqGoxr5"
      },
      "source": [
        "**A prediction system was built to predict whether a home team will win it's match or not.**\n",
        "\n",
        "Key to results data:\n",
        "* Div = League Division\n",
        "* Date = Match Date (dd/mm/yy)\n",
        "* Time = Time of match kick-off\n",
        "* HomeTeam = Home Team\n",
        "* Away team = Away Team\n",
        "* FTHG and HG = Full Time Home Team Goals\n",
        "* FTAG and AG = Full-Time Away Team Goals\n",
        "* FTR and Res = Full-Time Result (H=Home Win, D=Draw, A=Away Win)\n",
        "* HTHG = Half Time Home Team Goals\n",
        "* HTAG = Half Time Away Team Goals\n",
        "* HTR = Half Time Result (H=Home Win, D=Draw, A=Away Win)\n",
        "\n",
        "Match Statistics (where available)\n",
        "* Attendance = Crowd Attendance\n",
        "* Referee = Match Referee\n",
        "* HS = Home Team Shots\n",
        "* AS = Away Team Shots\n",
        "* HST = Home Team Shots on Target\n",
        "* AST = Away Team Shots on Target\n",
        "* HHW = Home Team Hit Woodwork\n",
        "* AHW = Away Team Hit Woodwork\n",
        "* HC = Home Team Corners\n",
        "* AC = Away Team Corners\n",
        "* HF = Home Team Fouls Committed\n",
        "* AF = Away Team Fouls Committed\n",
        "* HFKC = Home Team Free Kicks Conceded\n",
        "* AFKC = Away Team Free Kicks Conceded\n",
        "* HO = Home Team Offsides\n",
        "* AO = Away Team Offsides\n",
        "* HY = Home Team Yellow Cards\n",
        "* AY = Away Team Yellow Cards\n",
        "*HR = Home Team Red Cards\n",
        "AR = Away Team Red Cards\n",
        "HBP = Home Team Bookings Points (10 = yellow, 25 = red)\n",
        "ABP = Away Team Bookings Points (10 = yellow, 25 = red)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G11T2Zyoxr6"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urdAVT7goxr7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from datetime import datetime as dt\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf5m70Peoxr9"
      },
      "outputs": [],
      "source": [
        "# Read data from the CSV into a dataframe\n",
        "folder=''\n",
        "raw_data_1 = pd.read_csv(folder +'2000-01.csv')\n",
        "raw_data_2 = pd.read_csv(folder +'2001-02.csv')\n",
        "raw_data_3 = pd.read_csv(folder +'2002-03.csv')\n",
        "raw_data_4 = pd.read_csv(folder +'2003-04.csv')\n",
        "raw_data_5 = pd.read_csv(folder +'2004-05.csv')\n",
        "raw_data_6 = pd.read_csv(folder +'2005-06.csv')\n",
        "raw_data_7 = pd.read_csv(folder +'2006-07.csv')\n",
        "raw_data_8 = pd.read_csv(folder +'2007-08.csv')\n",
        "raw_data_9 = pd.read_csv(folder +'2008-09.csv')\n",
        "raw_data_10 = pd.read_csv(folder +'2009-10.csv')\n",
        "raw_data_11 = pd.read_csv(folder +'2010-11.csv')\n",
        "raw_data_12 = pd.read_csv(folder +'2011-12.csv')\n",
        "raw_data_13 = pd.read_csv(folder +'2012-13.csv')\n",
        "raw_data_14 = pd.read_csv(folder +'2013-14.csv')\n",
        "raw_data_15 = pd.read_csv(folder +'2014-15.csv')\n",
        "raw_data_16 = pd.read_csv(folder +'2015-16.csv')\n",
        "raw_data_17 = pd.read_csv(folder +'2016-17.csv')\n",
        "raw_data_18 = pd.read_csv(folder +'2017-18.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBa1Uga7oxr-"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Gets all the statistics related to gameplay\n",
        "\n",
        "columns_req = ['Date','HomeTeam','AwayTeam','FTHG','FTAG','FTR']\n",
        "\n",
        "playing_statistics_1 = raw_data_1[columns_req]\n",
        "playing_statistics_2 = raw_data_2[columns_req]\n",
        "playing_statistics_3 = raw_data_3[columns_req]\n",
        "playing_statistics_4 = raw_data_4[columns_req]\n",
        "playing_statistics_5 = raw_data_5[columns_req]\n",
        "playing_statistics_6 = raw_data_6[columns_req]\n",
        "playing_statistics_7 = raw_data_7[columns_req]\n",
        "playing_statistics_8 = raw_data_8[columns_req]\n",
        "playing_statistics_9 = raw_data_9[columns_req]\n",
        "playing_statistics_10 = raw_data_10[columns_req]\n",
        "playing_statistics_11 = raw_data_11[columns_req]\n",
        "playing_statistics_12 = raw_data_12[columns_req]\n",
        "playing_statistics_13 = raw_data_13[columns_req]\n",
        "playing_statistics_14 = raw_data_14[columns_req]\n",
        "playing_statistics_15 = raw_data_15[columns_req]\n",
        "playing_statistics_16 = raw_data_16[columns_req]\n",
        "playing_statistics_17 = raw_data_17[columns_req]\n",
        "playing_statistics_18 = raw_data_18[columns_req]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njmkYPnPoxr_"
      },
      "source": [
        "**GOALS SCORED AND CONCEDED AT THE END OF MATCHWEEK, ARRANGED BY TEAMS AND MATCHWEEK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_6W20Buoxr_"
      },
      "outputs": [],
      "source": [
        "# Gets the goals scored agg arranged by teams and matchweek\n",
        "def get_goals_scored(playing_stat):\n",
        "    # Create a dictionary with team names as keys\n",
        "    teams = {}\n",
        "    for i in playing_stat.groupby('HomeTeam').mean().T.columns:\n",
        "        teams[i] = []\n",
        "\n",
        "    # the value corresponding to keys is a list containing the match location.\n",
        "    for i in range(len(playing_stat)):\n",
        "        HTGS = playing_stat.iloc[i]['FTHG']\n",
        "        ATGS = playing_stat.iloc[i]['FTAG']\n",
        "        teams[playing_stat.iloc[i].HomeTeam].append(HTGS)\n",
        "        teams[playing_stat.iloc[i].AwayTeam].append(ATGS)\n",
        "\n",
        "    # Create a dataframe for goals scored where rows are teams and cols are matchweek.\n",
        "    GoalsScored = pd.DataFrame(data=teams, index = [i for i in range(1,39)]).T\n",
        "    GoalsScored[0] = 0\n",
        "    # Aggregate to get uptil that point\n",
        "    for i in range(2,39):\n",
        "        GoalsScored[i] = GoalsScored[i] + GoalsScored[i-1]\n",
        "    return GoalsScored\n",
        "\n",
        "\n",
        "\n",
        "# Gets the goals conceded agg arranged by teams and matchweek\n",
        "def get_goals_conceded(playing_stat):\n",
        "    # Create a dictionary with team names as keys\n",
        "    teams = {}\n",
        "    for i in playing_stat.groupby('HomeTeam').mean().T.columns:\n",
        "        teams[i] = []\n",
        "\n",
        "    # the value corresponding to keys is a list containing the match location.\n",
        "    for i in range(len(playing_stat)):\n",
        "        ATGC = playing_stat.iloc[i]['FTHG']\n",
        "        HTGC = playing_stat.iloc[i]['FTAG']\n",
        "        teams[playing_stat.iloc[i].HomeTeam].append(HTGC)\n",
        "        teams[playing_stat.iloc[i].AwayTeam].append(ATGC)\n",
        "\n",
        "    # Create a dataframe for goals scored where rows are teams and cols are matchweek.\n",
        "    GoalsConceded = pd.DataFrame(data=teams, index = [i for i in range(1,39)]).T\n",
        "    GoalsConceded[0] = 0\n",
        "    # Aggregate to get uptil that point\n",
        "    for i in range(2,39):\n",
        "        GoalsConceded[i] = GoalsConceded[i] + GoalsConceded[i-1]\n",
        "    return GoalsConceded\n",
        "\n",
        "def get_gss(playing_stat):\n",
        "    GC = get_goals_conceded(playing_stat)\n",
        "    GS = get_goals_scored(playing_stat)\n",
        "\n",
        "    j = 0\n",
        "    HTGS = []\n",
        "    ATGS = []\n",
        "    HTGC = []\n",
        "    ATGC = []\n",
        "\n",
        "    for i in range(380):\n",
        "        ht = playing_stat.iloc[i].HomeTeam\n",
        "        at = playing_stat.iloc[i].AwayTeam\n",
        "        HTGS.append(GS.loc[ht][j])\n",
        "        ATGS.append(GS.loc[at][j])\n",
        "        HTGC.append(GC.loc[ht][j])\n",
        "        ATGC.append(GC.loc[at][j])\n",
        "\n",
        "        if ((i + 1)% 10) == 0:\n",
        "            j = j + 1\n",
        "\n",
        "    playing_stat['HTGS'] = HTGS\n",
        "    playing_stat['ATGS'] = ATGS\n",
        "    playing_stat['HTGC'] = HTGC\n",
        "    playing_stat['ATGC'] = ATGC\n",
        "\n",
        "    return playing_stat\n",
        "\n",
        "\n",
        "# Apply to each dataset\n",
        "playing_statistics_1 = get_gss(playing_statistics_1)\n",
        "playing_statistics_2 = get_gss(playing_statistics_2)\n",
        "playing_statistics_3 = get_gss(playing_statistics_3)\n",
        "playing_statistics_4 = get_gss(playing_statistics_4)\n",
        "playing_statistics_5 = get_gss(playing_statistics_5)\n",
        "playing_statistics_6 = get_gss(playing_statistics_6)\n",
        "playing_statistics_7 = get_gss(playing_statistics_7)\n",
        "playing_statistics_8 = get_gss(playing_statistics_8)\n",
        "playing_statistics_9 = get_gss(playing_statistics_9)\n",
        "playing_statistics_10 = get_gss(playing_statistics_10)\n",
        "playing_statistics_11 = get_gss(playing_statistics_11)\n",
        "playing_statistics_12 = get_gss(playing_statistics_12)\n",
        "playing_statistics_13 = get_gss(playing_statistics_13)\n",
        "playing_statistics_14 = get_gss(playing_statistics_14)\n",
        "playing_statistics_15 = get_gss(playing_statistics_15)\n",
        "playing_statistics_16 = get_gss(playing_statistics_16)\n",
        "playing_statistics_17 = get_gss(playing_statistics_17)\n",
        "playing_statistics_18 = get_gss(playing_statistics_18)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcGTX9TZoxsB"
      },
      "source": [
        "**GET RESPECTIVE POINTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaPQM62RoxsB"
      },
      "outputs": [],
      "source": [
        "def get_points(result):\n",
        "    if result == 'W':\n",
        "        return 3\n",
        "    elif result == 'D':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def get_cuml_points(matchres):\n",
        "    matchres_points = matchres.applymap(get_points)\n",
        "    for i in range(2,39):\n",
        "        matchres_points[i] = matchres_points[i] + matchres_points[i-1]\n",
        "\n",
        "    matchres_points.insert(column =0, loc = 0, value = [0*i for i in range(20)])\n",
        "    return matchres_points\n",
        "\n",
        "\n",
        "def get_matchres(playing_stat):\n",
        "    # Create a dictionary with team names as keys\n",
        "    teams = {}\n",
        "    for i in playing_stat.groupby('HomeTeam').mean().T.columns:\n",
        "        teams[i] = []\n",
        "\n",
        "    # the value corresponding to keys is a list containing the match result\n",
        "    for i in range(len(playing_stat)):\n",
        "        if playing_stat.iloc[i].FTR == 'H':\n",
        "            teams[playing_stat.iloc[i].HomeTeam].append('W')\n",
        "            teams[playing_stat.iloc[i].AwayTeam].append('L')\n",
        "        elif playing_stat.iloc[i].FTR == 'A':\n",
        "            teams[playing_stat.iloc[i].AwayTeam].append('W')\n",
        "            teams[playing_stat.iloc[i].HomeTeam].append('L')\n",
        "        else:\n",
        "            teams[playing_stat.iloc[i].AwayTeam].append('D')\n",
        "            teams[playing_stat.iloc[i].HomeTeam].append('D')\n",
        "\n",
        "    return pd.DataFrame(data=teams, index = [i for i in range(1,39)]).T\n",
        "\n",
        "def get_agg_points(playing_stat):\n",
        "    matchres = get_matchres(playing_stat)\n",
        "    cum_pts = get_cuml_points(matchres)\n",
        "    HTP = []\n",
        "    ATP = []\n",
        "    j = 0\n",
        "    for i in range(380):\n",
        "        ht = playing_stat.iloc[i].HomeTeam\n",
        "        at = playing_stat.iloc[i].AwayTeam\n",
        "        HTP.append(cum_pts.loc[ht][j])\n",
        "        ATP.append(cum_pts.loc[at][j])\n",
        "\n",
        "        if ((i + 1)% 10) == 0:\n",
        "            j = j + 1\n",
        "\n",
        "    playing_stat['HTP'] = HTP\n",
        "    playing_stat['ATP'] = ATP\n",
        "    return playing_stat\n",
        "\n",
        "# Apply to each dataset\n",
        "playing_statistics_1 = get_agg_points(playing_statistics_1)\n",
        "playing_statistics_2 = get_agg_points(playing_statistics_2)\n",
        "playing_statistics_3 = get_agg_points(playing_statistics_3)\n",
        "playing_statistics_4 = get_agg_points(playing_statistics_4)\n",
        "playing_statistics_5 = get_agg_points(playing_statistics_5)\n",
        "playing_statistics_6 = get_agg_points(playing_statistics_6)\n",
        "playing_statistics_7 = get_agg_points(playing_statistics_7)\n",
        "playing_statistics_8 = get_agg_points(playing_statistics_8)\n",
        "playing_statistics_9 = get_agg_points(playing_statistics_9)\n",
        "playing_statistics_10 = get_agg_points(playing_statistics_10)\n",
        "playing_statistics_11 = get_agg_points(playing_statistics_11)\n",
        "playing_statistics_12 = get_agg_points(playing_statistics_12)\n",
        "playing_statistics_13 = get_agg_points(playing_statistics_13)\n",
        "playing_statistics_14 = get_agg_points(playing_statistics_14)\n",
        "playing_statistics_15 = get_agg_points(playing_statistics_15)\n",
        "playing_statistics_16 = get_agg_points(playing_statistics_16)\n",
        "playing_statistics_17 = get_agg_points(playing_statistics_17)\n",
        "playing_statistics_18 = get_agg_points(playing_statistics_18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPfCjsrwoxsD"
      },
      "source": [
        "**GET TEAM FORM:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSqdLowNoxsD"
      },
      "outputs": [],
      "source": [
        "def get_form(playing_stat,num):\n",
        "    form = get_matchres(playing_stat)\n",
        "    form_final = form.copy()\n",
        "    for i in range(num,39):\n",
        "        form_final[i] = ''\n",
        "        j = 0\n",
        "        while j < num:\n",
        "            form_final[i] += form[i-j]\n",
        "            j += 1\n",
        "    return form_final\n",
        "\n",
        "def add_form(playing_stat,num):\n",
        "    form = get_form(playing_stat,num)\n",
        "    h = ['M' for i in range(num * 10)]  # since form is not available for n MW (n*10)\n",
        "    a = ['M' for i in range(num * 10)]\n",
        "\n",
        "    j = num\n",
        "    for i in range((num*10),380):\n",
        "        ht = playing_stat.iloc[i].HomeTeam\n",
        "        at = playing_stat.iloc[i].AwayTeam\n",
        "\n",
        "        past = form.loc[ht][j]               # get past n results\n",
        "        h.append(past[num-1])                    # 0 index is most recent\n",
        "\n",
        "        past = form.loc[at][j]               # get past n results.\n",
        "        a.append(past[num-1])                   # 0 index is most recent\n",
        "\n",
        "        if ((i + 1)% 10) == 0:\n",
        "            j = j + 1\n",
        "\n",
        "    playing_stat['HM' + str(num)] = h\n",
        "    playing_stat['AM' + str(num)] = a\n",
        "\n",
        "\n",
        "    return playing_stat\n",
        "\n",
        "\n",
        "def add_form_df(playing_statistics):\n",
        "    playing_statistics = add_form(playing_statistics,1)\n",
        "    playing_statistics = add_form(playing_statistics,2)\n",
        "    playing_statistics = add_form(playing_statistics,3)\n",
        "    playing_statistics = add_form(playing_statistics,4)\n",
        "    playing_statistics = add_form(playing_statistics,5)\n",
        "    return playing_statistics\n",
        "\n",
        "# Make changes to df\n",
        "playing_statistics_1 = add_form_df(playing_statistics_1)\n",
        "playing_statistics_2 = add_form_df(playing_statistics_2)\n",
        "playing_statistics_3 = add_form_df(playing_statistics_3)\n",
        "playing_statistics_4 = add_form_df(playing_statistics_4)\n",
        "playing_statistics_5 = add_form_df(playing_statistics_5)\n",
        "playing_statistics_6 = add_form_df(playing_statistics_6)\n",
        "playing_statistics_7 = add_form_df(playing_statistics_7)\n",
        "playing_statistics_8 = add_form_df(playing_statistics_8)\n",
        "playing_statistics_9 = add_form_df(playing_statistics_9)\n",
        "playing_statistics_10 = add_form_df(playing_statistics_10)\n",
        "playing_statistics_11 = add_form_df(playing_statistics_11)\n",
        "playing_statistics_12 = add_form_df(playing_statistics_12)\n",
        "playing_statistics_13 = add_form_df(playing_statistics_13)\n",
        "playing_statistics_14 = add_form_df(playing_statistics_14)\n",
        "playing_statistics_15 = add_form_df(playing_statistics_15)\n",
        "playing_statistics_16 = add_form_df(playing_statistics_16)\n",
        "playing_statistics_17 = add_form_df(playing_statistics_17)\n",
        "playing_statistics_18 = add_form_df(playing_statistics_18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cao3Yqo2oxsE"
      },
      "outputs": [],
      "source": [
        "# Rearranging columns\n",
        "cols = ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTGS', 'ATGS', 'HTGC', 'ATGC', 'HTP', 'ATP', 'HM1', 'HM2', 'HM3',\n",
        "        'HM4', 'HM5', 'AM1', 'AM2', 'AM3', 'AM4', 'AM5' ]\n",
        "\n",
        "playing_statistics_1 = playing_statistics_1[cols]\n",
        "playing_statistics_2 = playing_statistics_2[cols]\n",
        "playing_statistics_3 = playing_statistics_3[cols]\n",
        "playing_statistics_4 = playing_statistics_4[cols]\n",
        "playing_statistics_5 = playing_statistics_5[cols]\n",
        "playing_statistics_6 = playing_statistics_6[cols]\n",
        "playing_statistics_7 = playing_statistics_7[cols]\n",
        "playing_statistics_8 = playing_statistics_8[cols]\n",
        "playing_statistics_9 = playing_statistics_9[cols]\n",
        "playing_statistics_10 = playing_statistics_10[cols]\n",
        "playing_statistics_11 = playing_statistics_11[cols]\n",
        "playing_statistics_12 = playing_statistics_12[cols]\n",
        "playing_statistics_13 = playing_statistics_13[cols]\n",
        "playing_statistics_14 = playing_statistics_14[cols]\n",
        "playing_statistics_15 = playing_statistics_15[cols]\n",
        "playing_statistics_16 = playing_statistics_16[cols]\n",
        "playing_statistics_17 = playing_statistics_17[cols]\n",
        "playing_statistics_18 = playing_statistics_18[cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy62yIyCoxsE"
      },
      "source": [
        "**Get MatchWeek:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXQUdhaqoxsF"
      },
      "outputs": [],
      "source": [
        "def get_mw(playing_stat):\n",
        "    j = 1\n",
        "    MatchWeek = []\n",
        "    for i in range(380):\n",
        "        MatchWeek.append(j)\n",
        "        if ((i + 1)% 10) == 0:\n",
        "            j = j + 1\n",
        "    playing_stat['MW'] = MatchWeek\n",
        "    return playing_stat\n",
        "\n",
        "playing_statistics_1 = get_mw(playing_statistics_1)\n",
        "playing_statistics_2 = get_mw(playing_statistics_2)\n",
        "playing_statistics_3 = get_mw(playing_statistics_3)\n",
        "playing_statistics_4 = get_mw(playing_statistics_4)\n",
        "playing_statistics_5 = get_mw(playing_statistics_5)\n",
        "playing_statistics_6 = get_mw(playing_statistics_6)\n",
        "playing_statistics_7 = get_mw(playing_statistics_7)\n",
        "playing_statistics_8 = get_mw(playing_statistics_8)\n",
        "playing_statistics_9 = get_mw(playing_statistics_9)\n",
        "playing_statistics_10 = get_mw(playing_statistics_10)\n",
        "playing_statistics_11 = get_mw(playing_statistics_11)\n",
        "playing_statistics_12 = get_mw(playing_statistics_12)\n",
        "playing_statistics_13 = get_mw(playing_statistics_13)\n",
        "playing_statistics_14 = get_mw(playing_statistics_14)\n",
        "playing_statistics_15 = get_mw(playing_statistics_15)\n",
        "playing_statistics_16 = get_mw(playing_statistics_16)\n",
        "playing_statistics_17 = get_mw(playing_statistics_17)\n",
        "playing_statistics_18 = get_mw(playing_statistics_18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq-oLCSnoxsF"
      },
      "source": [
        "**FINAL DATAFRAME**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fli68oS6oxsF"
      },
      "outputs": [],
      "source": [
        "playing_stat = pd.concat([playing_statistics_1,\n",
        "                          playing_statistics_2,\n",
        "                          playing_statistics_3,\n",
        "                          playing_statistics_4,\n",
        "                          playing_statistics_5,\n",
        "                          playing_statistics_6,\n",
        "                          playing_statistics_7,\n",
        "                          playing_statistics_8,\n",
        "                          playing_statistics_9,\n",
        "                          playing_statistics_10,\n",
        "                          playing_statistics_11,\n",
        "                          playing_statistics_12,\n",
        "                          playing_statistics_13,\n",
        "                          playing_statistics_14,\n",
        "                          playing_statistics_15,\n",
        "                          playing_statistics_16,\n",
        "                          playing_statistics_17,\n",
        "                          playing_statistics_18\n",
        "                          ], ignore_index=True)\n",
        "\n",
        "\n",
        "# Gets the form points.\n",
        "def get_form_points(string):\n",
        "    sum = 0\n",
        "    for letter in string:\n",
        "        sum += get_points(letter)\n",
        "    return sum\n",
        "\n",
        "playing_stat['HTFormPtsStr'] = playing_stat['HM1'] + playing_stat['HM2'] + playing_stat['HM3'] + playing_stat['HM4'] + playing_stat['HM5']\n",
        "playing_stat['ATFormPtsStr'] = playing_stat['AM1'] + playing_stat['AM2'] + playing_stat['AM3'] + playing_stat['AM4'] + playing_stat['AM5']\n",
        "\n",
        "playing_stat['HTFormPts'] = playing_stat['HTFormPtsStr'].apply(get_form_points)\n",
        "playing_stat['ATFormPts'] = playing_stat['ATFormPtsStr'].apply(get_form_points)\n",
        "\n",
        "# Identify Win/Loss Streaks if any.\n",
        "def get_3game_ws(string):\n",
        "    if string[-3:] == 'WWW':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_5game_ws(string):\n",
        "    if string == 'WWWWW':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_3game_ls(string):\n",
        "    if string[-3:] == 'LLL':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_5game_ls(string):\n",
        "    if string == 'LLLLL':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "playing_stat['HTWinStreak3'] = playing_stat['HTFormPtsStr'].apply(get_3game_ws)\n",
        "playing_stat['HTWinStreak5'] = playing_stat['HTFormPtsStr'].apply(get_5game_ws)\n",
        "playing_stat['HTLossStreak3'] = playing_stat['HTFormPtsStr'].apply(get_3game_ls)\n",
        "playing_stat['HTLossStreak5'] = playing_stat['HTFormPtsStr'].apply(get_5game_ls)\n",
        "\n",
        "playing_stat['ATWinStreak3'] = playing_stat['ATFormPtsStr'].apply(get_3game_ws)\n",
        "playing_stat['ATWinStreak5'] = playing_stat['ATFormPtsStr'].apply(get_5game_ws)\n",
        "playing_stat['ATLossStreak3'] = playing_stat['ATFormPtsStr'].apply(get_3game_ls)\n",
        "playing_stat['ATLossStreak5'] = playing_stat['ATFormPtsStr'].apply(get_5game_ls)\n",
        "\n",
        "playing_stat.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkpdhZWMoxsG"
      },
      "outputs": [],
      "source": [
        "# Get Goal Difference\n",
        "playing_stat['HTGD'] = playing_stat['HTGS'] - playing_stat['HTGC']\n",
        "playing_stat['ATGD'] = playing_stat['ATGS'] - playing_stat['ATGC']\n",
        "\n",
        "# Diff in points\n",
        "playing_stat['DiffPts'] = playing_stat['HTP'] - playing_stat['ATP']\n",
        "playing_stat['DiffFormPts'] = playing_stat['HTFormPts'] - playing_stat['ATFormPts']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQEp-Q7WoxsG"
      },
      "outputs": [],
      "source": [
        "# Scale DiffPts , DiffFormPts, HTGD, ATGD by Matchweek.\n",
        "cols = ['HTGD','ATGD','DiffPts','DiffFormPts','HTP','ATP']\n",
        "playing_stat.MW = playing_stat.MW.astype(float)\n",
        "\n",
        "for col in cols:\n",
        "    playing_stat[col] = playing_stat[col] / playing_stat.MW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mq9N4SuoxsH"
      },
      "outputs": [],
      "source": [
        "def only_hw(string):\n",
        "    if string == 'H':\n",
        "        return 'H'\n",
        "    else:\n",
        "        return 'NH'\n",
        "\n",
        "playing_stat['FTR'] = playing_stat.FTR.apply(only_hw)\n",
        "\n",
        "# Testing set (2015-16 season)\n",
        "playing_stat_test = playing_stat[5700:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8DLzLsPoxsI"
      },
      "outputs": [],
      "source": [
        "#saving the final dataset\n",
        "playing_stat.to_csv('final_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mFwzUupoxsI"
      },
      "outputs": [],
      "source": [
        "#saving the test set\n",
        "playing_stat_test.to_csv(\"test_set.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EctGwdloxsI"
      },
      "outputs": [],
      "source": [
        "#loading the final dataset\n",
        "dataset = pd.read_csv('final_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VYpi1NNoxsJ"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQEvYJQ1oxsK"
      },
      "outputs": [],
      "source": [
        "dataset.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8ATFJM1oxsL"
      },
      "source": [
        "### Correlation Matrix for dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb-0uSR1oxsL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(dataset.corr(), annot= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIbfcHtvoxsN"
      },
      "source": [
        "POSITIVE CORRELATION: If an increase in feature A leads to increase in feature B, then they are positively correlated. A value 1 means perfect positive correlation.\n",
        "\n",
        "NEGATIVE CORRELATION: If an increase in feature A leads to decrease in feature B, then they are negatively correlated. A value -1 means perfect negative correlation.\n",
        "\n",
        "Now lets say that two features are highly or perfectly correlated, so the increase in one leads to increase in the other. This means that both the features are containing highly similar information and there is very little or no variance in information. This is known as MultiColinearity as both of them contains almost the same information.\n",
        "\n",
        "So do you think we should use both of them as one of them is redundant. While making or training models, we should try to eliminate redundant features as it reduces training time and many such advantages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCW-zPUkoxsO"
      },
      "outputs": [],
      "source": [
        "# Remove few column\n",
        "dataset2 = dataset.copy().drop(columns =['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG',\n",
        "       'HTGS', 'ATGS', 'HTGC', 'ATGC',\n",
        "       'HM4', 'HM5','AM4', 'AM5', 'MW', 'HTFormPtsStr',\n",
        "       'ATFormPtsStr', 'HTFormPts', 'ATFormPts', 'HTWinStreak3',\n",
        "       'HTWinStreak5', 'HTLossStreak3', 'HTLossStreak5', 'ATWinStreak3',\n",
        "       'ATWinStreak5', 'ATLossStreak3', 'ATLossStreak5',\n",
        "       'DiffPts'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXpnsD_SoxsO"
      },
      "outputs": [],
      "source": [
        "dataset2.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejNNzPxJoxsP"
      },
      "outputs": [],
      "source": [
        "dataset2.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB1UdkQ5oxsQ"
      },
      "outputs": [],
      "source": [
        "#what is the win rate for the home team?\n",
        "\n",
        "# Total number of matches.\n",
        "n_matches = dataset2.shape[0]\n",
        "\n",
        "# Calculate number of features. -1 because we are saving one as the target variable (win/lose/draw)\n",
        "n_features = dataset2.shape[1] - 1\n",
        "\n",
        "# Calculate matches won by home team.\n",
        "n_homewins = len(dataset2[dataset2.FTR == 'H'])\n",
        "\n",
        "# Calculate win rate for home team.\n",
        "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
        "\n",
        "# Print the results\n",
        "print(\"Total number of matches: {}\".format(n_matches))\n",
        "print (\"Number of features: {}\".format(n_features))\n",
        "print( \"Number of matches won by home team: {}\".format(n_homewins))\n",
        "print (\"Win rate of home team: {:.2f}%\".format(win_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSyNvRCEoxsR"
      },
      "source": [
        "## Visualise the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIzuMfH9oxsR"
      },
      "outputs": [],
      "source": [
        "# Visualising distribution of data\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "#the scatter matrix is plotting each of the columns specified against each other column.\n",
        "#You would have observed that the diagonal graph is defined as a histogram, which means that in the\n",
        "#section of the plot matrix where the variable is against itself, a histogram is plotted.\n",
        "\n",
        "#Scatter plots show how much one variable is affected by another.\n",
        "#The relationship between two variables is called their correlation\n",
        "#negative vs positive correlation\n",
        "\n",
        "#HTGD - Home team goal difference\n",
        "#ATGD - away team goal difference\n",
        "#HTP - Home team points\n",
        "#ATP - Away team points\n",
        "#DiffFormPts Diff in points\n",
        "#DiffLP - Differnece in last years prediction\n",
        "\n",
        "scatter_matrix(dataset2[['HTGD','ATGD','HTP','ATP','DiffFormPts']], figsize=(15,15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVNk6bWPoxsS"
      },
      "outputs": [],
      "source": [
        "# Separate into feature set and target variable\n",
        "#FTR = Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
        "X_all = dataset2.drop(['FTR'],1)\n",
        "y_all = dataset2['FTR']\n",
        "\n",
        "# Standardising the data.\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "#Center to the mean and component wise scale to unit variance.\n",
        "cols = [['HTGD','ATGD','HTP','ATP']]\n",
        "for col in cols:\n",
        "    X_all[col] = scale(X_all[col])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHMGR8Dzoxsc"
      },
      "outputs": [],
      "source": [
        "#last 3 wins for both sides\n",
        "X_all.HM1 = X_all.HM1.astype('str')\n",
        "X_all.HM2 = X_all.HM2.astype('str')\n",
        "X_all.HM3 = X_all.HM3.astype('str')\n",
        "X_all.AM1 = X_all.AM1.astype('str')\n",
        "X_all.AM2 = X_all.AM2.astype('str')\n",
        "X_all.AM3 = X_all.AM3.astype('str')\n",
        "\n",
        "#we want continous vars that are integers for our input data, so lets remove any categorical vars\n",
        "def preprocess_features(X):\n",
        "    ''' Preprocesses the football data and converts catagorical variables into dummy variables. '''\n",
        "\n",
        "    # Initialize new output DataFrame\n",
        "    output = pd.DataFrame(index = X.index)\n",
        "\n",
        "    # Investigate each feature column for the data\n",
        "    for col, col_data in X.iteritems():\n",
        "\n",
        "        # If data type is categorical, convert to dummy variables\n",
        "        if col_data.dtype == object:\n",
        "            col_data = pd.get_dummies(col_data, prefix = col)\n",
        "\n",
        "        # Collect the revised columns\n",
        "        output = output.join(col_data)\n",
        "\n",
        "    return output\n",
        "\n",
        "X_all = preprocess_features(X_all)\n",
        "print (\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnGnOJCsoxsd"
      },
      "outputs": [],
      "source": [
        "X_all.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkP-IaEboxse"
      },
      "source": [
        "## Spliting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w53RBoduoxsl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Shuffle and split the dataset into training and testing set.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all,\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state = 2,\n",
        "                                                    stratify = y_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XCzrQRNoxsn"
      },
      "source": [
        "# Applying the Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eesH8uI1oxsn"
      },
      "outputs": [],
      "source": [
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktbZId9joxsn"
      },
      "outputs": [],
      "source": [
        "Y_pred = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl0q93XSoxso"
      },
      "outputs": [],
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_test, Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMakpZTHoxso"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(cm, annot=True,fmt='d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yh1BstQoxsp"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koG2c1n_oxsp"
      },
      "source": [
        "# Applying the SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST3nrNl7oxsq"
      },
      "outputs": [],
      "source": [
        "#fitting the SVM to the training set\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf',random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zkJP8yvoxsr"
      },
      "outputs": [],
      "source": [
        "#predicting result\n",
        "Y_pred = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gRyFNwAoxsr"
      },
      "outputs": [],
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_4G15CNoxsr"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(cm, annot=True, fmt='d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8TTOFZ1oxst"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2QjwCR3oxst"
      },
      "source": [
        "# Applying the RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27Ch3j2Boxst"
      },
      "outputs": [],
      "source": [
        "#fitting the RANDOM FOREST to the training se\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "classifier = RandomForestClassifier(criterion='gini',\n",
        "                             n_estimators=700,\n",
        "                             min_samples_split=10,\n",
        "                             min_samples_leaf=1,\n",
        "                             max_features='auto',\n",
        "                             oob_score=True,\n",
        "                             random_state=1,\n",
        "                             n_jobs=-1)\n",
        "classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHs3RIduoxsu"
      },
      "outputs": [],
      "source": [
        "#predicting result\n",
        "Y_pred = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w3uiFCIoxsv"
      },
      "outputs": [],
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "369IahFqoxsv"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(cm, annot=True, fmt='d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VHy8KCSoxsw"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCl7Nc1toxsw"
      },
      "source": [
        "# Applying the XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_a5dH7hoxsx"
      },
      "outputs": [],
      "source": [
        "# Fitting XGBoost to the Training set\n",
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier(seed=82)\n",
        "classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTAs1cfMoxsx"
      },
      "outputs": [],
      "source": [
        "# Predicting the Test set results\n",
        "Y_pred = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IG0v4G0Goxuh"
      },
      "outputs": [],
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7mLyUWAoxuj"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(cm, annot=True,fmt='d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_EL_XnLoxuk"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ceVC7rOoxul"
      },
      "source": [
        "**Clearly XGBoost seems like the best model as it has the highest F1 score and accuracy score on the test set.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SipfcL1foxum"
      },
      "source": [
        "# Tuning the parameters of XGBoost.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opLst5fRoxun"
      },
      "outputs": [],
      "source": [
        "# TODO: Import 'GridSearchCV' and 'make_scorer'\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# TODO: Create the parameters list you wish to tune\n",
        "parameters = { 'learning_rate' : [0.1],\n",
        "               'n_estimators' : [40],\n",
        "               'max_depth': [3],\n",
        "               'min_child_weight': [3],\n",
        "               'gamma':[0.4],\n",
        "               'subsample' : [0.8],\n",
        "               'colsample_bytree' : [0.8],\n",
        "               'scale_pos_weight' : [1],\n",
        "               'reg_alpha':[1e-5]\n",
        "             }\n",
        "\n",
        "def predict_labels(clf, features, target):\n",
        "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
        "\n",
        "    y_pred = clf.predict(features)\n",
        "\n",
        "    return f1_score(target, y_pred, pos_label='H'), sum(target == y_pred) / float(len(y_pred))\n",
        "\n",
        "\n",
        "# TODO: Initialize the classifier\n",
        "clf = xgb.XGBClassifier(seed=2)\n",
        "\n",
        "# TODO: Make an f1 scoring function using 'make_scorer'\n",
        "f1_scorer = make_scorer(f1_score,pos_label='H')\n",
        "\n",
        "# TODO: Perform grid search on the classifier using the f1_scorer as the scoring method\n",
        "grid_obj = GridSearchCV(clf,\n",
        "                        scoring=f1_scorer,\n",
        "                        param_grid=parameters,\n",
        "                        cv=5)\n",
        "\n",
        "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
        "grid_obj = grid_obj.fit(X_train,y_train)\n",
        "\n",
        "# Get the estimator\n",
        "clf = grid_obj.best_estimator_\n",
        "print(clf)\n",
        "\n",
        "# Report the final F1 score for training and testing after parameter tuning\n",
        "f1, acc = predict_labels(clf, X_train, y_train)\n",
        "print( \"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "\n",
        "f1, acc = predict_labels(clf, X_test, y_test)\n",
        "print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8cxSBcGoxuo"
      },
      "source": [
        "#### Probably little best!!!!!!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsxuaQvyoxuo"
      },
      "source": [
        "Accuracy is not soo good but it can improved.\n",
        "\n",
        "Actually it only depend upon past year match dataset,we can improve the accuracy by putting twitter data related to match, sentiment analysis, chances of player to play a specific match,player performace in recent series,etc.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM38fW-7oxup"
      },
      "source": [
        "I hope you find this kernel useful and enjoyable. If so please upVote\n",
        "\n",
        "Your comments and feedback are most welcome."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}